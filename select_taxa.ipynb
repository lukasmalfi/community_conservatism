{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath=\"insert/your/path\"\n",
    "taxname=\"microbes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the distance file with all pairwise tree branch length calculations\n",
    "df_mp=pd.read_feather(\"microbes_distances_99OTU.feather\", use_threads=True)\n",
    "\n",
    "df_mp.index=df_mp.columns\n",
    "\n",
    "\n",
    "#so we made Our first file with Distances now. Let's go on to figure out the distribtuion!\n",
    "\n",
    "\n",
    "rn2=df_mp.sample(n=3000,random_state=33)\n",
    "\n",
    "rn1=rn2.values.tolist()\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a = np.array([])\n",
    "\n",
    "for i in range(3000):\n",
    "    b = random.sample(rn1[i],3000)\n",
    "    a=np.append(a,b)\n",
    "\n",
    "#create a historgram with the approximate distance distribution and save it\n",
    "\n",
    "histo=np.histogram(a, bins=50)\n",
    "\n",
    "plt.hist(a,bins=50)\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(111)\n",
    "ax1.hist(a, bins=50)\n",
    "fig1.savefig(savepath+taxname+\"/plots/distplot_\"+taxname+\"_.png\")\n",
    "\n",
    "#MANUAL STEP: Check distirbution\n",
    "\n",
    "#IMPORTANT: Here we set the limit of which percentile we want to keep: E.G exclude the far right tail of the distribution, where we sometimes find wrongly \n",
    "#annotated taxonomic annotations or OTUs that don't belong th the phylum we are investigating.\n",
    "\n",
    "per=np.percentile(a,97)\n",
    "\n",
    "\n",
    "val=per\n",
    "\n",
    "a1=a[a<val]\n",
    "\n",
    "#the distrubtion excluding the right tails =3%) of distances, since we may not always be able to fill this bin (and it is uninformative)\n",
    "\n",
    "histo=np.histogram(a1, bins=50)\n",
    "\n",
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(111)\n",
    "ax2.hist(a1, bins=50)\n",
    "fig2.savefig(savepath+taxname+\"/plots/distplot_\"+taxname+\"_corr.png\")\n",
    "\n",
    "weights=histo[0]\n",
    "\n",
    "\n",
    "\n",
    "weights=(1/histo[0])/(sum(1/histo[0]))\n",
    "\n",
    "hi=histo[1]\n",
    "\n",
    "weights=weights*(1/max(weights))\n",
    "\n",
    "\n",
    "\n",
    "#need to add a check for duplicates and remove them\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#OLD VERSION\n",
    "\n",
    "#convert dataframe into numpy obj\n",
    "\n",
    "xy=df_mp.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "#select our OTUs, filling each bin with 500 OTUs\n",
    "\n",
    "otus=df_mp.index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "globall=[]\n",
    "otu_count_dict={}\n",
    "for binnr in range(len(histo[1])-1):\n",
    "\n",
    "\n",
    "    vals=[]\n",
    "    arr=np.nonzero((xy>histo[1][binnr])&(xy<histo[1][binnr+1]))\n",
    "\n",
    "    np.random.state=33\n",
    "\n",
    "    while len(vals)<500:\n",
    "        #select random otus\n",
    "        n=np.random.randint(0,len(arr[0]))\n",
    "        col_ind=arr[0][n]\n",
    "        row_ind=arr[1][n]\n",
    "        #get their identifiers\n",
    "        otu1=otus[col_ind]\n",
    "        otu2=otus[row_ind]\n",
    "        #calculate their tree branch distance\n",
    "        distance=xy[col_ind,row_ind]\n",
    "        \n",
    "        #count the occurences of each OLTU to avoid them being used in too many computations\n",
    "        if otu1 not in otu_count_dict.keys():\n",
    "            otu_count_dict[otu1]=1\n",
    "        else:\n",
    "            otu_count_dict[otu1]+=1\n",
    "        if otu2 not in otu_count_dict.keys():\n",
    "            otu_count_dict[otu2]=1\n",
    "        else:\n",
    "            otu_count_dict[otu2]+=1\n",
    "        #max 10 times an OTU can be used\n",
    "        if otu_count_dict[otu1] <10 and otu_count_dict[otu2] < 10:\n",
    "            #make sure we don't have duplicate pairs\n",
    "            if (otu1+ \" \" + otu2+ \" \" + str(distance)) not in vals: \n",
    "\n",
    "                    vals.append(otu1+ \" \" + otu2+ \" \" + str(distance))\n",
    "    #attach to global vals variable\n",
    "    globall.append(vals)\n",
    "    print(str(binnr)+\" done\")\n",
    "#lets set the pandas display value higher to observe the correct branch lengths\n",
    "\n",
    "vals=[]\n",
    "for x in globall:\n",
    "    for y in x:\n",
    "        vals.append(y)\n",
    "\n",
    "\n",
    "pd.set_option(\"display.precision\", 10)   \n",
    "\n",
    "dfdf=pd.DataFrame(columns=[\"Distance\"])\n",
    "\n",
    "dfdf[\"Distance\"]=vals\n",
    "\n",
    "\n",
    "dfdf=dfdf[\"Distance\"].str.split(\" \",expand=True)\n",
    "\n",
    "dfdf.columns=[\"OTU1\",\"OTU2\",\"Distance\",]\n",
    "\n",
    "\n",
    "dfdf[\"Distance\"]=dfdf[\"Distance\"].astype(float)\n",
    "\n",
    "\n",
    "#plot and save the final distribution of phylogebnetic distances we chose\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(111)\n",
    "ax1.hist(dfdf[\"Distance\"], bins=20)\n",
    "fig1.savefig(savepath+taxname+\"/plots/distplot_\"+taxname+\"_uniform.png\")\n",
    "\n",
    "#save the pairs and tree branch lengths selected\n",
    "\n",
    "df1str=dfdf.to_csv(header=True,sep=\"\\t\")\n",
    "f= open(savepath+taxname+\"/\" + taxname+\"_10k_99_dists.csv\",\"w+\")\n",
    "f.write(df1str)\n",
    "f.close()\n",
    "\n",
    "\n",
    "#create the shortnames for the OTU-pairs\n",
    "\n",
    "a=[]\n",
    "b=[]\n",
    "#if we have archaea:\n",
    "\n",
    "\n",
    "if \"Archaea\" in taxname:\n",
    "\n",
    "    for i in range(len(f2)):\n",
    "        a.append(re.sub(r'^.*?_99_', 'A99_', f2[\"OTU1\"].values[i]) + \" \" + re.sub(r'^.*?_99_', 'A99_', f2[\"OTU2\"].values[i]))\n",
    "       \n",
    "\n",
    "    dataframe_pairs1=pd.DataFrame(columns=[\"Pairs\"])\n",
    "\n",
    "    dataframe_pairs1[\"Pairs\"]=a\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    dataframe_pairs1=dataframe_pairs1[\"Pairs\"].str.split(\" \", expand=True)\n",
    "\n",
    "    dataframe_pairs1.columns=[\"OTU1\",\"OTU2\"]\n",
    "\n",
    "\n",
    "    p=[]\n",
    "    for i in range(len(f2)):\n",
    "        p.append(re.sub(r'^.*?_99_', 'A99_', dataframe_pairs1[\"OTU1\"].values[i]) + \" \" + re.sub(r'^.*?_99_', 'A99_', dataframe_pairs1[\"OTU2\"].values[i]))\n",
    "else:\n",
    "        #For Bacteria\n",
    "    for i in range(len(f2)):\n",
    "        a.append(re.sub(r'^.*?_99_', 'B99_', f2[\"OTU1\"].values[i]) + \" \" + re.sub(r'^.*?_99_', 'B99_', f2[\"OTU2\"].values[i]))\n",
    "       \n",
    "\n",
    "    dataframe_pairs1=pd.DataFrame(columns=[\"Pairs\"])\n",
    "\n",
    "    dataframe_pairs1[\"Pairs\"]=a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    dataframe_pairs1=dataframe_pairs1[\"Pairs\"].str.split(\" \", expand=True)\n",
    "\n",
    "\n",
    "    dataframe_pairs1.columns=[\"OTU1\",\"OTU2\"]\n",
    "\n",
    "    dataframe_pairs1\n",
    "\n",
    "    p=[]\n",
    "    for i in range(len(f2)):\n",
    "        p.append(re.sub(r'^.*?_99_', 'B99_', dataframe_pairs1[\"OTU1\"].values[i]) + \" \" + re.sub(r'^.*?_99_', 'B99_', dataframe_pairs1[\"OTU2\"].values[i]))\n",
    "\n",
    "dataframe_pairs=pd.DataFrame(columns=[\"Pairs\"])\n",
    "\n",
    "dataframe_pairs[\"Pairs\"]=p\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataframe_pairs=dataframe_pairs[\"Pairs\"].str.split(\" \", expand=True)\n",
    "\n",
    "\n",
    "dataframe_pairs.columns=[\"OTU1\",\"OTU2\"]\n",
    "\n",
    "#save the OTU-pairs with short identifier\n",
    "\n",
    "df1str=dataframe_pairs.to_csv(header=False, index=False, sep=\"\\t\")\n",
    "f= open(savepath+taxname+\"/\" + taxname+\"_pairs.tbl\",\"w+\")\n",
    "f.write(df1str)\n",
    "f.close()\n",
    "\n",
    "\n",
    "#Get a file with the taxonomy of our OTUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
